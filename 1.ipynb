{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "preliminary-conservative",
   "metadata": {},
   "source": [
    "## Bu çalışmada NCR (Uygunsuzluk Raporu) bilgileri ve NCR çeşidi verileri kullanılarak bir Doğal Dil İşleme (NLP) çalışması yapılmıştır.\n",
    "### Daha fazla bilgi için https://www.linkedin.com/in/seyidcem-karaka%C5%9F-534848188/\n",
    "\n",
    "---\n",
    "\n",
    "## In this study, a Natural Language Processing (NLP) study was conducted using NCR (Nonconformity Report) information and NCR type data.\n",
    "### For more information https://www.linkedin.com/in/seyidcem-karaka%C5%9F-534848188/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "musical-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_excel(\"hata_tipleri.xlsx\",engine=\"openpyxl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-difficulty",
   "metadata": {},
   "source": [
    "Verimizi yükleyelim.(Bendeki office sürümü eski olduğu için **engine** parametresi işimi gördü.)\n",
    "\n",
    "Let's upload our data. (Since the version of office I have is old, the ** engine ** parameter worked for me.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coupled-halifax",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hata</th>\n",
       "      <th>hata_tipi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Otopark temel süzgeç  kenarı beton bitiş kusuru</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Otopark temel soğuk derzden beton dökülmemiş k...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Otopark temeli üzeri mobil vinç ve beton pompa...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Otopark temel soğuk derz kesim yerinden beton ...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Betonarme imalat kalitesiyle ilgili uygulama s...</td>\n",
       "      <td>Yapım Yöntemine Uygunsuzluk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                hata  \\\n",
       "0    Otopark temel süzgeç  kenarı beton bitiş kusuru   \n",
       "1  Otopark temel soğuk derzden beton dökülmemiş k...   \n",
       "2  Otopark temeli üzeri mobil vinç ve beton pompa...   \n",
       "3  Otopark temel soğuk derz kesim yerinden beton ...   \n",
       "4  Betonarme imalat kalitesiyle ilgili uygulama s...   \n",
       "\n",
       "                     hata_tipi  \n",
       "0                İmalat Hatası  \n",
       "1                İmalat Hatası  \n",
       "2                İmalat Hatası  \n",
       "3                İmalat Hatası  \n",
       "4  Yapım Yöntemine Uygunsuzluk  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-framing",
   "metadata": {},
   "source": [
    "Verimizin ilk 5 satırına baktık.\n",
    "\n",
    "We look at the first 5 lines of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "serial-ready",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "İmalat Hatası                  568\n",
       "Yapım Yöntemine Uygunsuzluk    169\n",
       "Malzeme Hatası                  63\n",
       "Name: hata_tipi, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"hata_tipi\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-weekly",
   "metadata": {},
   "source": [
    "Hangi hata tipinden kaç adet var onu gördük.\n",
    "\n",
    "We see how many of which error type there are.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-magnet",
   "metadata": {},
   "source": [
    "Doğal dil işleme için **veri hazırlama/temizleme** sürecine başlayalım.\n",
    "\n",
    "Let's start the **data preparation / cleaning** process for natural language processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "following-worker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['acaba', 'ama', 'aslında', 'az', 'bazı', 'belki', 'biri', 'birkaç', 'birşey', 'biz', 'bu', 'çok', 'çünkü', 'da', 'daha', 'de', 'defa', 'diye', 'eğer', 'en', 'gibi', 'hem', 'hep', 'hepsi', 'her', 'hiç', 'için', 'ile', 'ise', 'kez', 'ki', 'kim', 'mı', 'mu', 'mü', 'nasıl', 'ne', 'neden', 'nerde', 'nerede', 'nereye', 'niçin', 'niye', 'o', 'sanki', 'şey', 'siz', 'şu', 'tüm', 've', 'veya', 'ya', 'yani']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "noktalama=string.punctuation\n",
    "etkisiz=stopwords.words(\"turkish\")\n",
    "\n",
    "print(noktalama)\n",
    "print(etkisiz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-boost",
   "metadata": {},
   "source": [
    "**nltk** paketinde türkçe işlemler için paket var.Noktalama işaretleri zaten çoğu dilde aynı (punctuation).\n",
    "\n",
    "**nltk** package contains package for Turkish transactions. The punctuation marks are already the same in most languages (punctuation).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-arena",
   "metadata": {},
   "source": [
    "### Gereksiz değerlerin atılması (çalışma mantığı gösterimi)\n",
    "\n",
    "### Discarding unnecessary values (working logic representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "foster-chocolate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otopark temel süzgeç  kenarı beton bitiş kusuru\n",
      "--------\n",
      "Otopark temel süzgeç kenarı beton bitiş kusuru \n",
      "****************\n",
      "Otopark temel soğuk derzden beton dökülmemiş kısıma çimento şerbeti sızması\n",
      "--------\n",
      "Otopark temel soğuk derzden beton dökülmemiş kısıma çimento şerbeti sızması \n",
      "****************\n",
      "Otopark temeli üzeri mobil vinç ve beton pompasından zemine motor yağı sızması ve temel yüzeyine zarar verilmesi\n",
      "--------\n",
      "Otopark temeli üzeri mobil vinç beton pompasından zemine motor yağı sızması temel yüzeyine zarar verilmesi \n",
      "****************\n",
      "Otopark temel soğuk derz kesim yerinden beton dökülmemiş bölüme beton ve çimento şerbeti sızması\n",
      "--------\n",
      "Otopark temel soğuk derz kesim yerinden beton dökülmemiş bölüme beton çimento şerbeti sızması \n",
      "****************\n",
      "Betonarme imalat kalitesiyle ilgili uygulama sorunları\n",
      "--------\n",
      "Betonarme imalat kalitesiyle ilgili uygulama sorunları \n",
      "****************\n"
     ]
    }
   ],
   "source": [
    "for d in data[\"hata\"].head(5):\n",
    "    print(d+\"\\n--------\")\n",
    "    temp=\"\"\n",
    "    for word in d.split():\n",
    "        if word not in etkisiz and not word.isnumeric():\n",
    "            temp+= word+\" \"\n",
    "    print(temp+\"\\n****************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-pollution",
   "metadata": {},
   "source": [
    "### Noktalama işaretlerinin atılması (çalışma mantığı gösterimi)\n",
    "\n",
    "### Discarding punctuation marks (working logic representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daily-bailey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zemin kat su basması hakkında\n",
      "------------\n",
      "Zemin kat su basması hakkında\n",
      "*****************\n",
      "VT14-15 asansör kuyu dibi döşemesine su akması, döşemedeki çelik profillerin ve baklava sacların paslanmaya başlaması \n",
      "------------\n",
      "VT1415 asansör kuyu dibi döşemesine su akması döşemedeki çelik profillerin ve baklava sacların paslanmaya başlaması \n",
      "*****************\n",
      "Çok amaçlı salon üzeri +6.00 kotu çelik döşemede INP300 kirişin iki ucunda civataların sıkılmaması ve sıkılmadan trapezin döşenmesi \n",
      "------------\n",
      "Çok amaçlı salon üzeri 600 kotu çelik döşemede INP300 kirişin iki ucunda civataların sıkılmaması ve sıkılmadan trapezin döşenmesi \n",
      "*****************\n",
      "Kule +209.00 kotu döşemesinde çatlak oluşması ve helikopter perdahı yapılmaması \n",
      "------------\n",
      "Kule 20900 kotu döşemesinde çatlak oluşması ve helikopter perdahı yapılmaması \n",
      "*****************\n",
      "Ayrık podyum 7.kat 3. etap (+35.80/+40.10 kotları arası) kolon ve perdeler, döşeme altı ve kat geneli kaba yapı kusurları\n",
      "------------\n",
      "Ayrık podyum 7kat 3 etap 35804010 kotları arası kolon ve perdeler döşeme altı ve kat geneli kaba yapı kusurları\n",
      "*****************\n"
     ]
    }
   ],
   "source": [
    "for d in data[\"hata\"].tail(5):\n",
    "    print(d+\"\\n------------\")\n",
    "    temp=\"\"\n",
    "    for word in d:\n",
    "        if word not in noktalama:\n",
    "            temp+= word\n",
    "    print(temp+\"\\n*****************\")\n",
    "    d=temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-snapshot",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Şimdi her bir veri için hem noktalamadan hem de gereksiz sözcüklerden kurtulup yeni bir DataFrame yapalım.\n",
    "\n",
    "Now let's get rid of both punctuation and unnecessary words for each data and make a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stuck-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data=pd.DataFrame(columns=[\"hata\"])\n",
    "for d in data[\"hata\"]:\n",
    "    a=\"\"\n",
    "    temp=\"\"\n",
    "    for word in d.split():\n",
    "        if word not in etkisiz and not word.isnumeric():\n",
    "            temp+= word+\" \"\n",
    "    for word in temp:\n",
    "        if word not in noktalama:\n",
    "            a+=word+\"\"\n",
    "    cleaned_data = cleaned_data.append({\"hata\":a},ignore_index=True)\n",
    "cleaned_data=cleaned_data.join(data[\"hata_tipi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aggregate-category",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hata</th>\n",
       "      <th>hata_tipi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Otopark temel süzgeç kenarı beton bitiş kusuru</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Otopark temel soğuk derzden beton dökülmemiş k...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Otopark temeli üzeri mobil vinç beton pompasın...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Otopark temel soğuk derz kesim yerinden beton ...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Betonarme imalat kalitesiyle ilgili uygulama s...</td>\n",
       "      <td>Yapım Yöntemine Uygunsuzluk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Zemin kat su basması hakkında</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>VT1415 asansör kuyu dibi döşemesine su akması ...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>Çok amaçlı salon üzeri 600 kotu çelik döşemede...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Kule 20900 kotu döşemesinde çatlak oluşması he...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Ayrık podyum 7kat 3 etap 35804010 kotları aras...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  hata  \\\n",
       "0      Otopark temel süzgeç kenarı beton bitiş kusuru    \n",
       "1    Otopark temel soğuk derzden beton dökülmemiş k...   \n",
       "2    Otopark temeli üzeri mobil vinç beton pompasın...   \n",
       "3    Otopark temel soğuk derz kesim yerinden beton ...   \n",
       "4    Betonarme imalat kalitesiyle ilgili uygulama s...   \n",
       "..                                                 ...   \n",
       "795                     Zemin kat su basması hakkında    \n",
       "796  VT1415 asansör kuyu dibi döşemesine su akması ...   \n",
       "797  Çok amaçlı salon üzeri 600 kotu çelik döşemede...   \n",
       "798  Kule 20900 kotu döşemesinde çatlak oluşması he...   \n",
       "799  Ayrık podyum 7kat 3 etap 35804010 kotları aras...   \n",
       "\n",
       "                       hata_tipi  \n",
       "0                  İmalat Hatası  \n",
       "1                  İmalat Hatası  \n",
       "2                  İmalat Hatası  \n",
       "3                  İmalat Hatası  \n",
       "4    Yapım Yöntemine Uygunsuzluk  \n",
       "..                           ...  \n",
       "795                İmalat Hatası  \n",
       "796                İmalat Hatası  \n",
       "797                İmalat Hatası  \n",
       "798                İmalat Hatası  \n",
       "799                İmalat Hatası  \n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-assignment",
   "metadata": {},
   "source": [
    "**cleaned_data** temizlenmiş veridir.\n",
    "\n",
    "**cleaned_data** is the cleared data.\n",
    "\n",
    "---\n",
    "bu dataframe'i bir .csv uzantılı dosyaya kaydedip yeniden çekelim.\n",
    "\n",
    "Let's save this dataframe to a .csv file and draw again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dangerous-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.to_csv(r\"./cleaned.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "verified-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data=pd.read_csv(\"cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pleased-journey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hata</th>\n",
       "      <th>hata_tipi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Otopark temel süzgeç kenarı beton bitiş kusuru</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Otopark temel soğuk derzden beton dökülmemiş k...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Otopark temeli üzeri mobil vinç beton pompasın...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Otopark temel soğuk derz kesim yerinden beton ...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Betonarme imalat kalitesiyle ilgili uygulama s...</td>\n",
       "      <td>Yapım Yöntemine Uygunsuzluk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>Zemin kat su basması hakkında</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>VT1415 asansör kuyu dibi döşemesine su akması ...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>Çok amaçlı salon üzeri 600 kotu çelik döşemede...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Kule 20900 kotu döşemesinde çatlak oluşması he...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Ayrık podyum 7kat 3 etap 35804010 kotları aras...</td>\n",
       "      <td>İmalat Hatası</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  hata  \\\n",
       "0      Otopark temel süzgeç kenarı beton bitiş kusuru    \n",
       "1    Otopark temel soğuk derzden beton dökülmemiş k...   \n",
       "2    Otopark temeli üzeri mobil vinç beton pompasın...   \n",
       "3    Otopark temel soğuk derz kesim yerinden beton ...   \n",
       "4    Betonarme imalat kalitesiyle ilgili uygulama s...   \n",
       "..                                                 ...   \n",
       "795                     Zemin kat su basması hakkında    \n",
       "796  VT1415 asansör kuyu dibi döşemesine su akması ...   \n",
       "797  Çok amaçlı salon üzeri 600 kotu çelik döşemede...   \n",
       "798  Kule 20900 kotu döşemesinde çatlak oluşması he...   \n",
       "799  Ayrık podyum 7kat 3 etap 35804010 kotları aras...   \n",
       "\n",
       "                       hata_tipi  \n",
       "0                  İmalat Hatası  \n",
       "1                  İmalat Hatası  \n",
       "2                  İmalat Hatası  \n",
       "3                  İmalat Hatası  \n",
       "4    Yapım Yöntemine Uygunsuzluk  \n",
       "..                           ...  \n",
       "795                İmalat Hatası  \n",
       "796                İmalat Hatası  \n",
       "797                İmalat Hatası  \n",
       "798                İmalat Hatası  \n",
       "799                İmalat Hatası  \n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-jacksonville",
   "metadata": {},
   "source": [
    "#### Bu veri ön işlemden çıktı ve işleme hazır durumda.\n",
    "\n",
    "#### This data has been preprocessed and ready for processing.\n",
    "---\n",
    "\n",
    "Verimizi eğitim ve test için ayrılarım.\n",
    "\n",
    "Lets separate our data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "corporate-reggae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560,)\n",
      "(240,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(cleaned_data[\"hata\"],cleaned_data[\"hata_tipi\"],test_size=0.3,random_state=2)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-disco",
   "metadata": {},
   "source": [
    "#### Eğitim ve test verisindeki dataların sayma vektörlerine bakalım.\n",
    "\n",
    "#### Let's look at the counting vectors of the data in training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dynamic-nerve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 1389)\n",
      "(240, 1389)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect=CountVectorizer()\n",
    "x_train_counts = count_vect.fit_transform(x_train)\n",
    "x_test_counts = count_vect.transform(x_test)\n",
    "print(x_train_counts.shape)\n",
    "print(x_test_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-girlfriend",
   "metadata": {},
   "source": [
    "640 adet cümle ve 1451 adet **token** var.\n",
    "\n",
    "There are 640 sentences and 1451 ** tokens **.\n",
    "\n",
    "---\n",
    "\n",
    "## Şimdi de **TF*IDF** vektörünü oluşturalım.\n",
    "\n",
    "### TF: kelimelerin 1 metinde kaç kere geçtiğini kodlar.\n",
    "\n",
    "### IDF: 1 kelimenin kaç farklı metinde geçtiğini kodlar.\n",
    "\n",
    "### TFIDF : 1 kelimenin döküman içindeki önemini gösterir.\n",
    "---\n",
    "\n",
    "## Now let's create the ** TF * IDF ** vector.\n",
    "\n",
    "### TF: codes how many times words occur in 1 text.\n",
    "\n",
    "### IDF: It encodes how many different text a word occurs.\n",
    "\n",
    "### TFIDF: It shows the importance of 1 word in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "starting-bullet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 1389)\n",
      "(240, 1389)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)\n",
    "x_test_tfidf = tfidf_transformer.transform(x_test_counts)\n",
    "print(x_train_tfidf.shape)\n",
    "print(x_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-chamber",
   "metadata": {},
   "source": [
    "### Şimdi çok modlu Naive Bayes sınıflandırıcı model kuralım.\n",
    "\n",
    "### Let's set up a multi-mode Naive Bayes classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "active-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-church",
   "metadata": {},
   "source": [
    "### Tahmin yapalım.\n",
    "\n",
    "### Let's guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "reserved-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-console",
   "metadata": {},
   "source": [
    "### Model performansına bakalım.\n",
    "\n",
    "### Let's look at the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "lasting-minnesota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7583333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-postcard",
   "metadata": {},
   "source": [
    "Veri seti ve modele bağlı olarak değişen bu oran iyi düzeydedir.\n",
    "\n",
    "This ratio, which varies depending on the data set and model, is at a good level.\n",
    "\n",
    "---\n",
    "\n",
    "random_state = 0 (veya herhangi bir sayı) yaptığımız için veri seti belli bir eyrden bölündü. Ama belki de eğitim için kötü bir yerden bölünde ve test kısmı bizi yanılttı. Bunun için random_state parametresini ortadan kaldırıp döngüye sokalım ve doğruluk oranını belirleyelim (K-fold gibi bir işlem).\n",
    "\n",
    "Since we made random_state = 0 (or any number), the data set was split by a certain task. But maybe it's a bad place for education and the testing part has misled us. For this, let's remove the random_state parameter and loop it and determine its accuracy (a process like K-fold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "spiritual-adaptation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!! 0.8 geçildi ===> 0.825\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    x_train,x_test,y_train,y_test=train_test_split(cleaned_data[\"hata\"],cleaned_data[\"hata_tipi\"],test_size=0.3)\n",
    "    count_vect=CountVectorizer()\n",
    "    x_train_counts = count_vect.fit_transform(x_train)\n",
    "    x_test_counts = count_vect.transform(x_test)\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    x_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)\n",
    "    x_test_tfidf = tfidf_transformer.transform(x_test_counts)\n",
    "    clf = MultinomialNB().fit(x_train_tfidf,y_train)\n",
    "    y_pred = clf.predict(x_test_tfidf)\n",
    "    if accuracy_score(y_test,y_pred) >0.81:\n",
    "        print(f\"!!!! 0.8 geçildi ===> {accuracy_score(y_test,y_pred)}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "entitled-monster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Tahmin                       Gerçek\n",
      "578  Yapım Yöntemine Uygunsuzluk  Yapım Yöntemine Uygunsuzluk\n",
      "278                İmalat Hatası                İmalat Hatası\n",
      "711                İmalat Hatası                İmalat Hatası\n",
      "25                 İmalat Hatası                İmalat Hatası\n",
      "172                İmalat Hatası                İmalat Hatası\n",
      "334                İmalat Hatası                İmalat Hatası\n",
      "471                İmalat Hatası                İmalat Hatası\n",
      "166                İmalat Hatası                İmalat Hatası\n",
      "705                İmalat Hatası                İmalat Hatası\n",
      "296                İmalat Hatası                İmalat Hatası\n",
      "190                İmalat Hatası                İmalat Hatası\n",
      "772                İmalat Hatası                İmalat Hatası\n",
      "441                İmalat Hatası                İmalat Hatası\n",
      "536                İmalat Hatası                İmalat Hatası\n",
      "330                İmalat Hatası  Yapım Yöntemine Uygunsuzluk\n",
      "302                İmalat Hatası                İmalat Hatası\n",
      "33                 İmalat Hatası  Yapım Yöntemine Uygunsuzluk\n",
      "36                 İmalat Hatası                İmalat Hatası\n",
      "573                İmalat Hatası  Yapım Yöntemine Uygunsuzluk\n",
      "209  Yapım Yöntemine Uygunsuzluk  Yapım Yöntemine Uygunsuzluk\n",
      "526                İmalat Hatası                İmalat Hatası\n",
      "691                İmalat Hatası                İmalat Hatası\n",
      "376  Yapım Yöntemine Uygunsuzluk  Yapım Yöntemine Uygunsuzluk\n",
      "657  Yapım Yöntemine Uygunsuzluk  Yapım Yöntemine Uygunsuzluk\n",
      "459                İmalat Hatası                İmalat Hatası\n",
      "491                İmalat Hatası                İmalat Hatası\n",
      "571                İmalat Hatası                İmalat Hatası\n",
      "350                İmalat Hatası                İmalat Hatası\n",
      "49                 İmalat Hatası                İmalat Hatası\n",
      "443                İmalat Hatası                İmalat Hatası\n",
      "İmalat Hatası                  216\n",
      "Yapım Yöntemine Uygunsuzluk     22\n",
      "Malzeme Hatası                   2\n",
      "Name: Tahmin, dtype: int64\n",
      "İmalat Hatası                  184\n",
      "Yapım Yöntemine Uygunsuzluk     40\n",
      "Malzeme Hatası                  16\n",
      "Name: Gerçek, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.DataFrame({\"Tahmin\":y_pred,\"Gerçek\":y_test})\n",
    "print(dataset.tail(30))\n",
    "print(dataset.Tahmin.value_counts())\n",
    "print(dataset.Gerçek.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
